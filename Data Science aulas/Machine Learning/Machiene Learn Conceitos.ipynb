{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING DO ZERO EM PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. INTRODUÇÃO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BREVE APRESENTAÇÃO: <br>\n",
    "- Graduado em Matemática pela USP, pós-graduado em Finanças pela FIA e mestre em Economia pela FGV;\n",
    "- Passagem por empresas como Itaú Unibanco, HSBC e Vivo. Atualmente, cientista de dados na startup de serviços, GetNinjas;\n",
    "- Experiência com riscos, cobrança, crédito e precificação;\n",
    "- Blog de Data Science: www.EstatSite.com.br;\n",
    "- Canal do Yukio (Youtube): https://www.youtube.com/channel/UCZDVnGEyggjuo2kgpmXdzGA;\n",
    "- Twitter: @EstatSite;\n",
    "- Podcast de Tecnologia: Pitacotech;\n",
    "- Github: www.github.com/yukioandre;\n",
    "\n",
    "O QUE É MACHINE LEARNING? <br>\n",
    "<img src='AI-ML-DS.png' style=\"width: 300px\">\n",
    "- Como o próprio nome já diz, estamos criando máquinas que aprendam (no caso, com dados);\n",
    "- Exemplo 1: Um filtro de spam que é capaz de identificar caracteres \"estranhos\" e que sejam indícios de que aquele e-mail é um spam é um programa de aprendizado de máquinas. Exemplo 2: Um programa que seja capaz de identificar se uma avaliação está elogiando ou insultando o estabelecimento também é um aprendizado de máquinas. Por isso aprendizado de máquinas é um campo da Inteligência Artificial - estamos tratando de máquinas que aprendem.\n",
    "- Polêmica: Por mais que ainda exista relutância de algumas pessoas, machine learning não é estatística/matemática com um nome mais chique;\n",
    "- Machine learning é sobre predições, pouco esforço humano e aprendizado com os dados;\n",
    "- Cases famosos: modelo de predição de assintomáticos com Covid; competição para criação do modelo de recomendação da Netflix; predição de Alzheimer.\n",
    "- Principais tipos de aprendizado: Supervisionado e Não-Supervisionado.\n",
    "\n",
    "O MERCADO DE MACHINE LEARNING: <br>\n",
    "- Muito recente, em alto crescimento;\n",
    "- Alta remuneração (não aquelas dos jornais, mas ainda alta se comparada com a média de outras áreas);\n",
    "- Áreas e cargos ainda em construção, em constante mudança;\n",
    "- Foco em aprendizado constante: 90% dos cientistas de dados  (Coursera, Datacamp, Udacity, Alura, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CARREGA BIBLIOTECAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "Pattern matched multiple keys",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Pcyes_User\\OneDrive\\Documentos\\My projects\\Data Science\\Ciencia de dados\\Machine Learning Projeto\\tutorial_ML_do_zero_youtube.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pcyes_User/OneDrive/Documentos/My%20projects/Data%20Science/Ciencia%20de%20dados/Machine%20Learning%20Projeto/tutorial_ML_do_zero_youtube.ipynb#ch0000004?line=18'>19</a>\u001b[0m \u001b[39m#### Settings ###########\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pcyes_User/OneDrive/Documentos/My%20projects/Data%20Science/Ciencia%20de%20dados/Machine%20Learning%20Projeto/tutorial_ML_do_zero_youtube.ipynb#ch0000004?line=19'>20</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m\"\u001b[39m\u001b[39mmax_colwidth\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1000\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Pcyes_User/OneDrive/Documentos/My%20projects/Data%20Science/Ciencia%20de%20dados/Machine%20Learning%20Projeto/tutorial_ML_do_zero_youtube.ipynb#ch0000004?line=20'>21</a>\u001b[0m pd\u001b[39m.\u001b[39;49mset_option(\u001b[39m\"\u001b[39;49m\u001b[39mmax_rows\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m20\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pcyes_User/OneDrive/Documentos/My%20projects/Data%20Science/Ciencia%20de%20dados/Machine%20Learning%20Projeto/tutorial_ML_do_zero_youtube.ipynb#ch0000004?line=21'>22</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m\"\u001b[39m\u001b[39mmax_columns\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1000\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pcyes_User/OneDrive/Documentos/My%20projects/Data%20Science/Ciencia%20de%20dados/Machine%20Learning%20Projeto/tutorial_ML_do_zero_youtube.ipynb#ch0000004?line=22'>23</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m\"\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_config\\config.py:256\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__func__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_config\\config.py:149\u001b[0m, in \u001b[0;36m_set_option\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_set_option() got an unexpected keyword argument \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkwarg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    148\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(args[::\u001b[39m2\u001b[39m], args[\u001b[39m1\u001b[39m::\u001b[39m2\u001b[39m]):\n\u001b[1;32m--> 149\u001b[0m     key \u001b[39m=\u001b[39m _get_single_key(k, silent)\n\u001b[0;32m    151\u001b[0m     o \u001b[39m=\u001b[39m _get_registered_option(key)\n\u001b[0;32m    152\u001b[0m     \u001b[39mif\u001b[39;00m o \u001b[39mand\u001b[39;00m o\u001b[39m.\u001b[39mvalidator:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_config\\config.py:116\u001b[0m, in \u001b[0;36m_get_single_key\u001b[1;34m(pat, silent)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39mraise\u001b[39;00m OptionError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such keys(s): \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(pat)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(keys) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m OptionError(\u001b[39m\"\u001b[39m\u001b[39mPattern matched multiple keys\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    117\u001b[0m key \u001b[39m=\u001b[39m keys[\u001b[39m0\u001b[39m]\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m silent:\n",
      "\u001b[1;31mOptionError\u001b[0m: Pattern matched multiple keys"
     ]
    }
   ],
   "source": [
    "# Para manipulacao dos dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# para graficos\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sweetviz as sv # !pip install sweetviz\n",
    "\n",
    "# para modelagem\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#### Settings ###########\n",
    "pd.set_option(\"max_colwidth\", 1000)\n",
    "pd.set_option(\"max_rows\", 20)\n",
    "pd.set_option(\"max_columns\", 1000)\n",
    "pd.set_option(\"precision\", 2)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "plt.style.use(\"classic\")\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PRIMEIRAS IMPRESSÕES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais sobre os campos do dataset:\n",
    "- Age (numeric)\n",
    "- Sex (text: male, female)\n",
    "- Job (numeric: 0 — unskilled and non-resident, 1 — unskilled and resident, 2 — skilled, 3 — highly skilled)\n",
    "- Housing (text: own, rent, or free)\n",
    "- Saving accounts (text — little, moderate, quite rich, rich)\n",
    "- Checking account (numeric, in DM — Deutsch Mark)\n",
    "- Credit amount (numeric, in DM)\n",
    "- Duration (numeric, in month)\n",
    "- Purpose (text: car, furniture/equipment, radio/TV, domestic appliances, repairs, education, business, vacation/others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega dataset\n",
    "df = pd.read_csv(\"german_credit_data.csv\", index_col=0)  # sep = ';', decimal = ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ve as primeiras linhas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ve as ultimas linhas\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# informação das variáveis (tipo, valores nulos, memoria que o objeto ta consumindo, etc)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f-string\n",
    "print(f\"O dataset possui {df.shape[0]} linhas e {df.shape[1]} colunas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como acessar os valores de shape:\n",
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar f-string dentro de queries\n",
    "import pandasql as ps\n",
    "\n",
    "filtro_idade = 70\n",
    "query = f\"\"\"\n",
    "select * from df\n",
    "where age < {filtro_idade}\n",
    "\"\"\"\n",
    "\n",
    "ps.sqldf(query, locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessar elementos: loc e o iloc\n",
    "df.iloc[0:4, 0:7]  # repara: está acessando um intervalo aberto na direita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outro modo de acessar elementos, usando nome da coluna\n",
    "df.loc[0:3, \"Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se quiser trazeer mais de uma coluna\n",
    "df.loc[0:3, [\"Age\", \"Sex\", \"Job\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# também pode ir pelo nome da coluna como índice\n",
    "novo_dataframe = df[[\"Age\", \"Housing\"]]\n",
    "novo_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatística descritiva\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E se quiser a estatística descritiva por grupo?\n",
    "df.groupby(\"Sex\")[\"Age\", \"Credit amount\", \"Duration\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Purpose\")[\"Age\", \"Credit amount\", \"Duration\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % de missing\n",
    "df.isna().mean() # se quisesse preencher, poderia usar fillna() \n",
    "\n",
    "# (ver post 'Classificador de Estilo Musical' lá no blog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total de missing por variavel\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# olhando as variáveis categóricas\n",
    "df.Housing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver o percentual:\n",
    "df.Housing.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegando os nomes das colunas\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtros\n",
    "# Query para lógica\n",
    "# 1)\n",
    "df.query(\"Age > 70\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)\n",
    "homens_velhos = df.query(\" Age > 70 & Sex == 'male' \")\n",
    "homens_velhos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método para tentar inferir se a variável é categórica\n",
    "provavel_categorica = {}\n",
    "\n",
    "for var in df.columns:\n",
    "    provavel_categorica[var] = 1.0 * df[var].nunique() / df[var].count() < 0.03\n",
    "\n",
    "provavel_categorica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relembrando\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Target\"] = np.where(df[\"Risk\"] == \"bad\", 1, 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Risk\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ANÁLISE EXPLORATÓRIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT COM PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(8, 4))\n",
    "_ = df.Target.value_counts().plot(kind=\"bar\")\n",
    "_ = plt.title(\"Nº de Clientes por Tipo de Risco\")\n",
    "_ = plt.ylim(0, 750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df.groupby(\"Target\")[\"Age\"].mean().plot(kind=\"bar\")\n",
    "_ = plt.title(\"Idade Média por Tipo de Risco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOTS COM MATPLOTLIB (FOCO NA HIERARQUIA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='matplotlib_framework.png' style=\"width: 500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veja como o gráfico vai sendo construído por partes\n",
    "_ = plt.figure(figsize=(6, 4))\n",
    "_ = plt.xlabel(\"Idade\")\n",
    "_ = plt.ylabel(\"Quantidade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note que vamos adicionando elementos ao desenho\n",
    "_ = plt.figure(figsize=(7, 4))\n",
    "_ = plt.hist(data=df, x=\"Age\", bins=20, rwidth=0.9, color=\"red\")\n",
    "_ = plt.xlabel(\"Idade\")\n",
    "_ = plt.title(\"Histograma para Idade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT COM SEABORN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.relplot(\n",
    "    x=\"Duration\",\n",
    "    y=\"Credit amount\",\n",
    "    hue=\"Target\",\n",
    "    palette=[\"purple\", \"blue\"],\n",
    "    size=\"Age\",\n",
    "    data=df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de contagem por categoria\n",
    "_ = sns.catplot(x=\"Housing\", kind=\"count\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DASHES AUTOMATIZADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dashboard com UMA única linha\n",
    "reporte = sv.analyze(df)\n",
    "reporte.show_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MODELAGEM DE MACHINE LEARNING: RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, um exemplo simples de árvore de decisão:\n",
    "\n",
    "<img src='arvore_de_decisao.png'>\n",
    "\n",
    "Mais sobre o modelo, você encontra aqui: https://estatsite.com.br/2016/06/11/1970/\n",
    "\n",
    "Agora, vejamos a Random Forest, um algoritmo baseado em árvores de decisão:\n",
    "\n",
    "<img src='Random_forest_diagram_complete.png'>\n",
    "\n",
    "RF combina a simplicidade das árvores de decisão com a flexibilidade de aprender de amostras novas (menor risco de overfitting).\n",
    "\n",
    "Como funciona a Random Forest:\n",
    "- Coletamos uma amostra do dataset original, podendo haver repetições;\n",
    "- Começamos a construção de uma árvore de decisão a partir do dataset gerado pela amostragem acima;\n",
    "- Na hora de selecionar qual a feature do primeiro nó (=root node), consideramos um subconjunto das features disponíveis no dataset;\n",
    "- Na hora de escolher a feature do nó seguinte, também selecionamos a partir de um subconjunto das variáveis que restaram;\n",
    "- Seguimos fazendo isso até finalizar a árvore;\n",
    "- Note: o subconjunto de features pode ter tamanho 2, 3, ..., n. É preciso escolher o que gera melhor desempenho;\n",
    "- Pegue o processo e repita centenas de vezes. I.e., construímos centenas de árvores de decisão.\n",
    "- Como usamos as árvores?\n",
    "- Pegue o primeiro data point (o primeiro \"indivíduo\" do nosso conjunto de dados) e rode ele na primeira árvore. Suponha que a gente esteja construindo um modelo para previsão de bom ou mau pagador. A previsão da primeira árvore é que o primeiro indivíduo é um mau pagador. Aí, rodamos para a segunda árvore. Ela também diz que ele será um bom pagador. Repetimos isso para todas árvores. Vemos qual opção recebeu mais votos. Como a maioria das árvores teve como previsão que o indivíduo seria um bom pagador, nossa previsão é que ele será um bom pagador.\n",
    "\n",
    "Termo importante:\n",
    "- Ensemble learning: Uso de múltiplos algoritmos para obter melhor desempenho preditivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos listar as features que vamos utilizar\n",
    "features = [\"Age\", \"Job\", \"Credit amount\", \"Purpose\", \"Housing\", \"Duration\"]\n",
    "target = \"Target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, dividimos antes de qualquer pré-processamento\n",
    "X = df[features]  # Features\n",
    "y = df[target]  # Labels\n",
    "\n",
    "# Divide em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=999\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisamos tratar as variáveis categóricas (Cuidado quando for numérica)\n",
    "cat_features = [\"Job\", \"Housing\", \"Purpose\"]\n",
    "num_features = [\"Age\", \"Credit amount\", \"Duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=cat_features)\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF = RandomForestClassifier()  # instanciar (= inicializar, criar o objeto)\n",
    "clf_RF.fit(X_train, y_train)  # treina o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplica no teste\n",
    "y_pred = clf_RF.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metricas de avaliacao\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Acurácia: \" + str(accuracy_score(y_test, y_pred)))  # acertos ao todo\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\n",
    "    \"F1 Score: {}\".format(f1_score(y_test, y_pred))\n",
    ")  # indica poucos falsos positivos e falsos negativos, quanto mais próximo de 1, melhor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Matriz de Confusão : \\n\" + str(confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Positive: \" + str(tp))\n",
    "print(\"True Negative: \" + str(tn))\n",
    "print(\"False Positive: \" + str(fp))\n",
    "print(\"False Negative: \" + str(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "21 / (21 + 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURVA ROC: calcula fpr e tpr para vários limiares\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# probabilidades\n",
    "# probs = clf_RF.predict_proba(X_test)\n",
    "\n",
    "y_scores = cross_val_predict(clf_RF, X_test, y_test)\n",
    "\n",
    "# obtem fpr, tpr e limites\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE IMPORTANCE\n",
    "feature_imp = pd.Series(clf_RF.feature_importances_, index=X_train.columns).sort_values(\n",
    "    ascending=False\n",
    ")\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bar plot\n",
    "_ = plt.figure(figsize=(10, 6))\n",
    "_ = sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "\n",
    "# Add labels to your graph\n",
    "_ = plt.xlabel(\"Feature Importance Score\")\n",
    "_ = plt.ylabel(\"Features\")\n",
    "_ = plt.title(\"Visualizing Important Features\")\n",
    "_ = plt.savefig(\"rf_features.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "\n",
    "# Tunando os hiperparâmetros:\n",
    "model_params = {\n",
    "    # randomly sample numbers from 4 to 204 estimators\n",
    "    \"n_estimators\": randint(4, 200),\n",
    "    # normally distributed max_features, with mean .25 stddev 0.1, bounded between 0 and 1\n",
    "    \"max_features\": truncnorm(a=0, b=1, loc=0.25, scale=0.1),\n",
    "    # uniform distribution from 0.01 to 0.2 (0.01 + 0.199)\n",
    "    \"min_samples_split\": uniform(0.01, 0.199),\n",
    "}\n",
    "\n",
    "# create random forest classifier model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# set up random search meta-estimator\n",
    "# this will train 100 models over 5 folds of cross validation (500 models total)\n",
    "clf = RandomizedSearchCV(rf_model, model_params, n_iter=10, cv=5, random_state=1)\n",
    "\n",
    "# train the random search meta-estimator to find the best model out of 100 candidates\n",
    "model = clf.fit(X_train, y_train)\n",
    "\n",
    "# print winning set of hyperparameters\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(model.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qual combinação de parâmetros trouxe melhor resultado:\n",
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_random = RandomForestClassifier(\n",
    "    max_features=0.3124639258611636,\n",
    "    min_samples_split=0.05068599769657197,\n",
    "    n_estimators=160,\n",
    ")\n",
    "\n",
    "clf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_random = clf_random.predict(X_test)\n",
    "\n",
    "print(\"Acurácia: \" + str(accuracy_score(y_test, y_pred_random)))\n",
    "\n",
    "print(\"F1 Score: {}\".format(f1_score(y_test, y_pred_random)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
